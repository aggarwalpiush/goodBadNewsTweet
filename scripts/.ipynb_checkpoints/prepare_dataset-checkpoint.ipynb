{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import codecs\n",
    "from classes.agreement_confidence import ConfidentIAA\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from time import sleep\n",
    "import subprocess\n",
    "import os\n",
    "from twarc import Twarc\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = '/Users/aggarwalpiush/github_repos/tweetnewsdetection/data/step_two/labelled/v1/annotate_with_conf.csv'\n",
    "input_file2 = '/Users/aggarwalpiush/github_repos/tweetnewsdetection/data/step_two/labelled/v2/ann_with_confidence.csv'\n",
    "ctl_file1 = '/Users/aggarwalpiush/github_repos/tweetnewsdetection/data/step_two/labelled/v1/id_tweetid_ctl.csv'\n",
    "ctl_file2 = '/Users/aggarwalpiush/github_repos/tweetnewsdetection/data/step_two/labelled/v2/id_tweetid_ctl.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5237\n"
     ]
    }
   ],
   "source": [
    "ctl_data = {}\n",
    "with codecs.open(ctl_file1, 'r', 'utf-8') as ctl_obj:\n",
    "    for i,data in enumerate(ctl_obj):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        data = data.rstrip('\\r\\n')\n",
    "        if int(data.split(',')[0]) not in ctl_data.keys():\n",
    "            ctl_data[int(data.split(',')[0])] = int(data.split(',')[-5])\n",
    "print(len(ctl_data.keys()))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10474\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(ctl_file2, 'r', 'utf-8') as ctl_obj:\n",
    "    for i,data in enumerate(ctl_obj):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        data = data.rstrip('\\r\\n')\n",
    "        if int(data.split(',')[0]) not in ctl_data.keys():\n",
    "            ctl_data[int(data.split(',')[0])] = int(data.split(',')[-5])\n",
    "print(len(ctl_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2172753144 1069567808768401408\n",
      "2172753145 1069193513009537024\n",
      "2172753146 1070164651890085888\n",
      "2172753147 1069562021060984832\n",
      "2172753148 1069830790492483586\n",
      "2172753149 1070193455320715264\n",
      "2172753150 1069170501837250562\n",
      "2172753151 1069818948621910016\n",
      "2172753152 1069513279934844933\n",
      "2172753153 1069458981637287936\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k,v in ctl_data.items():\n",
    "    print(k,v)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100083214901637126"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctl_data[2178483001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_list = []\n",
    "with codecs.open(input_file1, 'r', 'utf-8') as in_obj:\n",
    "    for i,data in enumerate(in_obj):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        data_array = data.rstrip('\\r\\n').split(',')\n",
    "        data_array[1] = 0 if data_array[1]== 'deny' else 1\n",
    "        data_array[2] = data_array[2].replace('-','0')\n",
    "        data_array[2] = data_array[2].replace('\\\\','')\n",
    "        data_array[2] = data_array[2].replace('p','0')\n",
    "        if not data_array[2].isdigit():\n",
    "            data_array[2] = 50 \n",
    "        data_array[2] = int(data_array[2])\n",
    "        in_data_list.append(data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(input_file2, 'r', 'utf-8') as in_obj:\n",
    "    for i,data in enumerate(in_obj):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        data_array = data.rstrip('\\r\\n').split(',')\n",
    "        data_array[1] = 0 if data_array[1]== 'deny' else 1\n",
    "        data_array[2] = data_array[2].replace('-','0')\n",
    "        data_array[2] = data_array[2].replace('\\\\','')\n",
    "        data_array[2] = data_array[2].replace('p','0')\n",
    "        if not data_array[2].isdigit():\n",
    "            data_array[2] = 50 \n",
    "        data_array[2] = int(data_array[2])\n",
    "        in_data_list.append(data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2178477838', 1, 70],\n",
       " ['2178477840', 0, 60],\n",
       " ['2178477837', 0, 80],\n",
       " ['2178477839', 1, 80],\n",
       " ['2178477839', 1, 100],\n",
       " ['2178477840', 1, 50],\n",
       " ['2178477838', 1, 100],\n",
       " ['2178477837', 0, 100],\n",
       " ['2178477841', 1, 55],\n",
       " ['2178477842', 1, 60]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24673"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = {}\n",
    "for annotation in in_data_list:\n",
    "    if int(annotation[0]) in subjects.keys():\n",
    "        subjects[int(annotation[0])].append(annotation[1])\n",
    "    else:\n",
    "        subjects[int(annotation[0])] = [annotation[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7212"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjects.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2178477838 [1, 1, 1]\n",
      "Counter({1: 3})\n",
      "2178477840 [0, 1, 0, 1, 0, 0, 0]\n",
      "Counter({0: 5, 1: 2})\n",
      "2178477837 [0, 0, 0]\n",
      "Counter({0: 3})\n",
      "2178477839 [1, 1, 1]\n",
      "Counter({1: 3})\n",
      "2178477841 [1, 1, 0, 1]\n",
      "Counter({1: 3, 0: 1})\n",
      "2178477842 [1, 1, 1]\n",
      "Counter({1: 3})\n",
      "2178477844 [1, 1, 1]\n",
      "Counter({1: 3})\n",
      "2178477843 [0, 0, 0]\n",
      "Counter({0: 3})\n",
      "2178477848 [0, 0, 0]\n",
      "Counter({0: 3})\n",
      "2178477847 [1, 1, 0, 0, 1, 1, 0]\n",
      "Counter({1: 4, 0: 3})\n",
      "2178477846 [0, 0, 0]\n",
      "Counter({0: 3})\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k,v in subjects.items():\n",
    "    print(k,v)\n",
    "    count += 1\n",
    "    print(Counter(v))\n",
    "    if count == 11:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[946893879344852994, 946463523957346304, 946786031495413760, 948268958054080512, 945059633705684993, 944556040833634306, 944963629501202432, 944668571971416064, 943835379538518016, 944267245970165760]\n",
      "6959\n",
      "6959\n"
     ]
    }
   ],
   "source": [
    "valid_subjects = []\n",
    "valid_label = []\n",
    "for k,v in subjects.items():\n",
    "        #print(k)\n",
    "        if len(v) >=3:\n",
    "            if 0 not in Counter(v).keys():\n",
    "               # print(1)\n",
    "                #print(k)\n",
    "                if k in ctl_data.keys():\n",
    "                    valid_subjects.append(ctl_data[k])\n",
    "                    valid_label.append(1)\n",
    "                else:\n",
    "                    assert('Tweet not found')\n",
    "            elif 1 not in Counter(v).keys():\n",
    "                #print(2)\n",
    "                #print(k)\n",
    "                if k in ctl_data.keys():\n",
    "                    valid_subjects.append(ctl_data[k])\n",
    "                    valid_label.append(0)\n",
    "                else:\n",
    "                    assert('Tweet not found')\n",
    "            elif Counter(v)[0] > Counter(v)[1]:\n",
    "                if float(Counter(v)[0]/len(v)) >= 0.7:\n",
    "                    #print(3)\n",
    "                    #print(k)\n",
    "                    if k in ctl_data.keys():\n",
    "                        valid_subjects.append(ctl_data[k])\n",
    "                        valid_label.append(0)\n",
    "                    else:\n",
    "                        assert('Tweet not found')\n",
    "            elif float(Counter(v)[1]/len(v)) >= 0.7:\n",
    "                    #print(4)\n",
    "                    #print(k)\n",
    "                    if k in ctl_data.keys():\n",
    "                        valid_subjects.append(ctl_data[k])\n",
    "                        valid_label.append(1)\n",
    "                    else:\n",
    "                        assert('Tweet not found')\n",
    "print(valid_subjects[:10])\n",
    "print(len(valid_subjects))\n",
    "print(len(valid_label))\n",
    "save_dir = '/Users/aggarwalpiush/github_repos/tweetnewsdetection/data/step_two/classification_data/text/'\n",
    "with codecs.open(save_dir + 'labels.txt', 'w', 'utf-8') as labels_obj:\n",
    "    for i, lab in enumerate(valid_label):\n",
    "        labels_obj.write('%s\\t%s\\n' %(valid_subjects[i],lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/aggarwalpiush/Documents/alfred/pheme-twitter-conversation-collection-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'/Users/aggarwalpiush/Documents/alfred/pheme-twitter-conversation-collection-master\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.check_output('pwd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "cmd = \"php get.thread.php 948268958054080512\"\n",
    "p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "if p.stderr.read().decode('utf-8') == '':\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token_secret='NsYYs0vWROLWY3i5YVvDiFZyy0UOAiqcohQtzxyCKz3Kl'\n",
    "access_token='4508853492-m0atItHuYTlo71xyic5V2EVe7Rjifyv5UWg6dke'\n",
    "consumer_secret='fPMJbt8tjWtcmc6R2dBwn3l6KCMt7GpSSl14bgKwMtL4vLivdn'\n",
    "consumer_key='HtHdVPLo5qktFFXfYNEUcCfXf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump's 'Back to the Moon' Directive Leaves Some Scientists with Mixed Feelings Mine from #AGU17 via @spacedotcom @AlanStern https://t.co/uKYDtW08jI https://t.co/3SINjt9cSp\n",
      "Hundreds of Geological Survey scientists restricted from attending annual meeting of @theAGU by current administration: https://t.co/E6jURoYbkZ #AGU17\n",
      "Maryland high school student Liza Goldberg has developed what might be the worldâ€™s first satellite-based early warning system to determine where mangroves are threatened. She presented her work at #AGU17. @washingtonpost @GabrielPopkin https://t.co/dnfvtlHtfW\n"
     ]
    }
   ],
   "source": [
    "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "for tweet in t.hydrate(['946463523957346304', '946786031495413760', '948268958054080512']):\n",
    "    print(tweet[\"full_text\"].rstrip('\\r\\n').replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946893879344852994\n"
     ]
    }
   ],
   "source": [
    "tweet_exp = '946893879344852994'\n",
    "tweet_dir = './data/' + tweet_exp + '/reactions/'\n",
    "for f in glob.glob(tweet_dir + \"*.json\"):\n",
    "    print(os.path.basename(f.replace('.json','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tweets 6959\n",
      "already scraped 6854\n"
     ]
    }
   ],
   "source": [
    "text_dir = '/Users/aggarwalpiush/github_repos/tweetnewsdetection/data/step_two/classification_data/text/'\n",
    "flaw_dir = '/Users/aggarwalpiush/github_repos/tweetnewsdetection/data/step_two/classification_data/flaw/'\n",
    "text_reply_dir = '/Users/aggarwalpiush/github_repos/tweetnewsdetection/data/step_two/classification_data/text_rply/'\n",
    "scraped_tweets = set(sorted(glob.glob(text_dir + \"*.txt\"), key=os.path.getmtime))\n",
    "available_tweets = [os.path.basename(tw.replace('.txt','')) for tw in scraped_tweets]\n",
    "print('total tweets %s' %(len(valid_subjects)))\n",
    "print('already scraped %s' %len(available_tweets))\n",
    "for i,tweetid in enumerate(valid_subjects):\n",
    "    if str(tweetid) in available_tweets:\n",
    "        continue\n",
    "    cmd = \"php get.thread.php \" + str(tweetid)\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "    if p.stderr.read().decode('utf-8') != '':\n",
    "        with codecs.open(flaw_dir + 'flaw_tweets.txt', 'a', 'utf-8') as flaw_obj:\n",
    "            flaw_obj.write(str(tweetid)+'\\n')\n",
    "    else:\n",
    "        tweet_dir = './data/' + str(tweetid) + '/reactions/'\n",
    "        all_reactions = sorted(glob.glob(tweet_dir + \"*.json\"), key=os.path.getmtime)\n",
    "        if len(all_reactions) == 0:\n",
    "            with codecs.open(flaw_dir + 'flaw_tweets.txt', 'a', 'utf-8') as flaw_obj:\n",
    "                flaw_obj.write(str(tweetid)+'\\n')\n",
    "            continue\n",
    "        print(tweetid)\n",
    "        tweet_with_replies = []\n",
    "        for f in all_reactions:\n",
    "            tweet_with_replies.append(os.path.basename(f.replace('.json','')))\n",
    "        with codecs.open(text_reply_dir + str(tweetid) +'.txt', 'w', 'utf-8') as withrep_obj:\n",
    "            with codecs.open(text_dir + str(tweetid) +'.txt', 'w', 'utf-8') as text_obj:\n",
    "                count = 0\n",
    "                for tweet in t.hydrate(tweet_with_replies):\n",
    "                    count += 1\n",
    "                    if count == 1:\n",
    "                        text_obj.write(tweet[\"full_text\"].rstrip('\\r\\n').replace('\\n', ''))\n",
    "                    withrep_obj.write(tweet[\"full_text\"].rstrip('\\r\\n').replace('\\n', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python mlib_demo",
   "language": "python",
   "name": "mlib_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
